"""
Script th·ª±c thi pipeline hu·∫•n luy·ªán v√† ƒë√°nh gi√° v·ªõi c√°c ph∆∞∆°ng ph√°p
chia d·ªØ li·ªáu kh√°c nhau ƒë·ªÉ so s√°nh hi·ªáu su·∫•t
"""

import os
import sys
import argparse
import subprocess
import json
import numpy as np
import matplotlib.pyplot as plt

def run_training(model, split_type, train_ratio=0.8, epochs=20, batch_size=32, seed=42):
    """
    Ch·∫°y script hu·∫•n luy·ªán v·ªõi c√°c th√¥ng s·ªë c·ª• th·ªÉ
    """
    print(f"\n{'='*80}")
    print(f"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh {model} v·ªõi ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu {split_type}")
    print(f"{'='*80}")
    
    # T·∫°o l·ªánh ch·∫°y
    cmd = [
        "python", "train/train_with_splits.py",
        "--model", model,
        "--split_type", split_type,
        "--train_ratio", str(train_ratio),
        "--epochs", str(epochs),
        "--batch_size", str(batch_size),
        "--seed", str(seed)
    ]
    
    # Ch·∫°y l·ªánh
    try:
        subprocess.run(cmd, check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå L·ªói khi ch·∫°y hu·∫•n luy·ªán: {e}")
        return False

def compare_results(models=['lstm', 'transformer'], split_types=['random', 'dependent', 'independent']):
    """
    So s√°nh k·∫øt qu·∫£ hu·∫•n luy·ªán gi·ªØa c√°c ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu
    """
    # L∆∞u k·∫øt qu·∫£ F1 ƒë·ªÉ so s√°nh
    results = {}
    
    # Duy·ªát qua c√°c m√¥ h√¨nh v√† ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu
    for model in models:
        results[model] = {}
        
        for split_type in split_types:
            # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file k·∫øt qu·∫£
            result_dir = os.path.join('results', f'{split_type}_split')
            history_file = os.path.join('results', f'{"ConvNeXtLSTMLite" if model == "lstm" else "ConvNeXtTransformerLite"}_history.npz')
            
            # N·∫øu kh√¥ng t√¨m th·∫•y file k·∫øt qu·∫£, b·ªè qua
            if not os.path.exists(history_file):
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho {model} v·ªõi ph∆∞∆°ng ph√°p {split_type}")
                continue
            
            # ƒê·ªçc d·ªØ li·ªáu l·ªãch s·ª≠ hu·∫•n luy·ªán
            history = np.load(history_file)
            val_f1s = history['val_f1s']
            best_f1 = val_f1s.max()
            
            # L∆∞u k·∫øt qu·∫£
            results[model][split_type] = best_f1
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print("\n" + "="*80)
    print("üìä K·∫æT QU·∫¢ SO S√ÅNH C√ÅC PH∆Ø∆†NG PH√ÅP CHIA D·ªÆ LI·ªÜU")
    print("="*80)
    
    # T·∫°o header
    header = ["M√¥ h√¨nh"] + split_types
    print(f"{header[0]:<15}", end="")
    for split in header[1:]:
        print(f"{split:<15}", end="")
    print()
    
    # In d√≤ng ngƒÉn c√°ch
    print("-"*15*len(header))
    
    # In d·ªØ li·ªáu
    for model in models:
        print(f"{model:<15}", end="")
        for split in split_types:
            if split in results[model]:
                print(f"{results[model][split]:.4f}       ", end="")
            else:
                print(f"N/A            ", end="")
        print()
    
    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    plt.figure(figsize=(12, 6))
    
    bar_width = 0.25
    index = np.arange(len(split_types))
    
    for i, model in enumerate(models):
        f1_values = [results[model].get(split, 0) for split in split_types]
        plt.bar(index + i*bar_width, f1_values, bar_width, label=model)
    
    plt.xlabel('Ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu')
    plt.ylabel('F1 Score')
    plt.title('So s√°nh F1 Score gi·ªØa c√°c ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu')
    plt.xticks(index + bar_width/2, split_types)
    plt.legend()
    
    # L∆∞u bi·ªÉu ƒë·ªì
    os.makedirs('results/comparison', exist_ok=True)
    plt.savefig('results/comparison/split_methods_comparison.png')
    plt.close()
    
    print(f"\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì so s√°nh t·∫°i results/comparison/split_methods_comparison.png")
    
    # L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON
    with open('results/comparison/split_methods_comparison.json', 'w') as f:
        json.dump(results, f, indent=4)
    
    print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ so s√°nh d∆∞·ªõi d·∫°ng JSON t·∫°i results/comparison/split_methods_comparison.json")

def main(args):
    """
    H√†m ch√≠nh c·ªßa script
    """
    # Ki·ªÉm tra c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
    if not os.path.exists('checkpoints'):
        os.makedirs('checkpoints', exist_ok=True)
    
    if not os.path.exists('results'):
        os.makedirs('results', exist_ok=True)
    
    # Ch·∫°y hu·∫•n luy·ªán cho t·ª´ng ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu
    for split_type in args.split_types:
        # Ch·∫°y v·ªõi LSTM
        if 'lstm' in args.models:
            run_training(
                model='lstm',
                split_type=split_type,
                train_ratio=args.train_ratio,
                epochs=args.epochs,
                batch_size=args.batch_size,
                seed=args.seed
            )
        
        # Ch·∫°y v·ªõi Transformer
        if 'transformer' in args.models:
            run_training(
                model='transformer',
                split_type=split_type,
                train_ratio=args.train_ratio,
                epochs=args.epochs,
                batch_size=args.batch_size,
                seed=args.seed
            )
    
    # So s√°nh k·∫øt qu·∫£
    if args.compare:
        compare_results(models=args.models, split_types=args.split_types)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Ch·∫°y pipeline v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu kh√°c nhau")
    parser.add_argument('--models', nargs='+', default=['lstm', 'transformer'], 
                       choices=['lstm', 'transformer'],
                       help='Danh s√°ch c√°c m√¥ h√¨nh c·∫ßn ch·∫°y')
    parser.add_argument('--split_types', nargs='+', default=['random', 'dependent', 'independent'],
                       choices=['random', 'dependent', 'independent'],
                       help='Danh s√°ch c√°c ph∆∞∆°ng ph√°p chia d·ªØ li·ªáu')
    parser.add_argument('--train_ratio', type=float, default=0.8, 
                       help='T·ª∑ l·ªá d·ªØ li·ªáu d√πng cho hu·∫•n luy·ªán (m·∫∑c ƒë·ªãnh: 0.8)')
    parser.add_argument('--epochs', type=int, default=20, 
                       help='S·ªë epochs cho m·ªói l·∫ßn hu·∫•n luy·ªán')
    parser.add_argument('--batch_size', type=int, default=32, 
                       help='K√≠ch th∆∞·ªõc batch')
    parser.add_argument('--seed', type=int, default=42, 
                       help='Seed ng·∫´u nhi√™n')
    parser.add_argument('--compare', action='store_true', 
                       help='So s√°nh k·∫øt qu·∫£ sau khi hu·∫•n luy·ªán')
    
    args = parser.parse_args()
    main(args)
