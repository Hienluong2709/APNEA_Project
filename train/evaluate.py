"""
Script Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh ConvNeXtTransformerLite
"""

import os
import sys
import argparse
import torch
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# ThÃªm Ä‘Æ°á»ng dáº«n gá»‘c vÃ o sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Import cÃ¡c module
from models.convnext_transformer_lite import ConvNeXtTransformerLite
from dataset.lazy_apnea_dataset import LazyApneaSingleDataset as LazyApneaDataset
try:
    from utils.visualization import plot_confusion_matrix, plot_ahi_comparison
except ImportError:
    print("âš ï¸ CÃ¡c module trong utils khÃ´ng tÃ¬m tháº¥y, Ä‘ang Ä‘á»‹nh nghÄ©a láº¡i cÃ¡c hÃ m cáº§n thiáº¿t...")
    
    def plot_confusion_matrix(y_true, y_pred, classes, save_path=None):
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path)
            print(f"ğŸ“Š ÄÃ£ lÆ°u confusion matrix táº¡i: {save_path}")
        else:
            plt.show()
        plt.close()
    
    def plot_ahi_comparison(true_ahi, pred_ahi, patient_ids=None, save_path=None):
        plt.figure(figsize=(12, 6))
        plt.scatter(true_ahi, pred_ahi, alpha=0.7)
        max_val = max(max(true_ahi), max(pred_ahi))
        plt.plot([0, max_val], [0, max_val], 'k--')
        plt.xlabel('AHI thá»±c táº¿')
        plt.ylabel('AHI dá»± Ä‘oÃ¡n')
        plt.title('So sÃ¡nh AHI thá»±c táº¿ vÃ  dá»± Ä‘oÃ¡n')
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path)
            print(f"ğŸ“Š ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ AHI táº¡i: {save_path}")
        else:
            plt.show()
        plt.close()

def calculate_ahi_from_predictions(y_true, y_pred, block_duration_sec=30):
    """
    TÃ­nh AHI tá»« nhÃ£n thá»±c táº¿ vÃ  nhÃ£n dá»± Ä‘oÃ¡n.
    """
    # Äáº£m báº£o y_pred lÃ  0 hoáº·c 1
    if y_pred.dtype != int:
        y_pred = (y_pred > 0.5).astype(int)

    # TÃ­nh sá»‘ giá»
    total_hours = (len(y_true) * block_duration_sec) / 3600
    
    # TÃ­nh AHI
    true_apnea_count = np.sum(y_true)
    pred_apnea_count = np.sum(y_pred)
    
    true_ahi = true_apnea_count / total_hours if total_hours > 0 else 0
    pred_ahi = pred_apnea_count / total_hours if total_hours > 0 else 0
    
    # CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
    mae = abs(true_ahi - pred_ahi)
    rmse = np.sqrt((true_ahi - pred_ahi)**2)
    
    metrics = {
        "mae": mae,
        "rmse": rmse
    }
    
    return true_ahi, pred_ahi, metrics

def classify_osa_severity(ahi):
    """
    PhÃ¢n loáº¡i má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a OSA dá»±a trÃªn AHI
    """
    if ahi < 5:
        return "Normal"
    elif ahi < 15:
        return "Mild"
    elif ahi < 30:
        return "Moderate"
    else:
        return "Severe"

def evaluate_model(model, test_loader, device='cuda'):
    """
    ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test
    """
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch_idx, (x, y) in enumerate(tqdm(test_loader, desc="Evaluating")):
            x, y = x.to(device), y.to(device)
            pred = model(x)
            preds = pred.argmax(1).detach().cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(y.cpu().numpy())
    
    # TÃ­nh cÃ¡c metrics
    accuracy = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='weighted')
    precision = precision_score(all_labels, all_preds, average='weighted')
    recall = recall_score(all_labels, all_preds, average='weighted')
    
    # TÃ­nh AHI vÃ  so sÃ¡nh
    true_ahi, pred_ahi, ahi_metrics = calculate_ahi_from_predictions(all_labels, all_preds)
    
    # TÃ­nh phÃ¢n loáº¡i OSA dá»±a trÃªn AHI
    true_severity = classify_osa_severity(true_ahi)
    pred_severity = classify_osa_severity(pred_ahi)
    
    # PhÃ¢n bá»‘ nhÃ£n vÃ  dá»± Ä‘oÃ¡n
    unique_labels, label_counts = np.unique(all_labels, return_counts=True)
    unique_preds, pred_counts = np.unique(all_preds, return_counts=True)
    
    # In káº¿t quáº£
    print("\n===== Káº¾T QUáº¢ ÄÃNH GIÃ =====")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"AHI thá»±c táº¿: {true_ahi:.2f}, Má»©c Ä‘á»™: {true_severity}")
    print(f"AHI dá»± Ä‘oÃ¡n: {pred_ahi:.2f}, Má»©c Ä‘á»™: {pred_severity}")
    print(f"MAE AHI: {ahi_metrics['mae']:.2f}")
    print(f"RMSE AHI: {ahi_metrics['rmse']:.2f}")
    print(f"PhÃ¢n bá»‘ nhÃ£n thá»±c táº¿: {dict(zip(unique_labels, label_counts))}")
    print(f"PhÃ¢n bá»‘ nhÃ£n dá»± Ä‘oÃ¡n: {dict(zip(unique_preds, pred_counts))}")
    
    # Váº½ confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    print(f"Confusion Matrix:\n{cm}")
    
    # Táº¡o thÆ° má»¥c káº¿t quáº£
    results_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'evaluation_results')
    os.makedirs(results_dir, exist_ok=True)
    
    # Váº½ biá»ƒu Ä‘á»“
    plot_confusion_matrix(
        all_labels, all_preds, 
        classes=['KhÃ´ng apnea', 'Apnea'], 
        save_path=os.path.join(results_dir, 'confusion_matrix.png')
    )
    
    # LÆ°u káº¿t quáº£ dÆ°á»›i dáº¡ng CSV
    results = {
        'Metric': ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'True AHI', 'Predicted AHI', 'MAE AHI', 'RMSE AHI'],
        'Value': [accuracy, f1, precision, recall, true_ahi, pred_ahi, ahi_metrics['mae'], ahi_metrics['rmse']]
    }
    pd.DataFrame(results).to_csv(os.path.join(results_dir, 'metrics.csv'), index=False)
    
    return {
        'accuracy': accuracy,
        'f1': f1,
        'precision': precision,
        'recall': recall,
        'true_ahi': true_ahi,
        'pred_ahi': pred_ahi,
        'mae_ahi': ahi_metrics['mae'],
        'rmse_ahi': ahi_metrics['rmse'],
        'confusion_matrix': cm
    }

def main():
    parser = argparse.ArgumentParser(description='ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh ConvNeXtTransformerLite')
    parser.add_argument('--data_dir', type=str, default='../data/blocks', help='ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a dá»¯ liá»‡u test')
    parser.add_argument('--model_path', type=str, default=None, help='ÄÆ°á»ng dáº«n Ä‘áº¿n file mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n')
    parser.add_argument('--batch_size', type=int, default=64, help='KÃ­ch thÆ°á»›c batch')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu', help='Thiáº¿t bá»‹ Ä‘Ã¡nh giÃ¡')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    
    args = parser.parse_args()
    
    # Khá»Ÿi táº¡o random seed
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # Chuyá»ƒn Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i thÃ nh tuyá»‡t Ä‘á»‘i
    data_dir = os.path.abspath(args.data_dir)
    
    # Táº¡o dataset vÃ  dataloader
    test_dataset = LazyApneaDataset(data_dir)
    test_loader = DataLoader(
        test_dataset, 
        batch_size=args.batch_size, 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    print(f"ğŸ“Š Test dataset: {len(test_dataset)} máº«u")
    
    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh
    model = ConvNeXtTransformerLite(
        num_classes=2, 
        embed_dim=128, 
        num_heads=8, 
        num_transformer_layers=4, 
        dropout=0.3
    ).to(args.device)
    
    # TÃ¬m mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if args.model_path is None:
        # TÃ¬m trong thÆ° má»¥c checkpoints
        checkpoints_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'checkpoints')
        
        # Æ¯u tiÃªn: SWA > Best_F1 > Best
        model_paths = [
            os.path.join(checkpoints_dir, 'ConvNeXtTransformerLite_swa.pth'),
            os.path.join(checkpoints_dir, 'ConvNeXtTransformerLite_best_f1.pth'),
            os.path.join(checkpoints_dir, 'ConvNeXtTransformerLite_best.pth')
        ]
        
        for path in model_paths:
            if os.path.exists(path):
                args.model_path = path
                break
        
        if args.model_path is None:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n!")
            return
    
    # Load mÃ´ hÃ¬nh
    print(f"ğŸ“‚ Äang load mÃ´ hÃ¬nh tá»« {args.model_path}...")
    model.load_state_dict(torch.load(args.model_path, map_location=args.device))
    
    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
    print(f"ğŸ§ª Äang Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn {args.device}...")
    metrics = evaluate_model(model, test_loader, device=args.device)
    
    print("âœ… ÄÃ¡nh giÃ¡ hoÃ n táº¥t!")

if __name__ == "__main__":
    main()
