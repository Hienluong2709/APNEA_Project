"""
Script hu·∫•n luy·ªán m√¥ h√¨nh ConvNeXtTransformerLite v√† t√≠nh to√°n ch·ªâ s·ªë AHI 
theo ph∆∞∆°ng ph√°p Dependent Subject v·ªõi c√°c k·ªπ thu·∫≠t ti√™n ti·∫øn
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, ConcatDataset, WeightedRandomSampler
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
from tqdm import tqdm
import seaborn as sns
import copy
import random
import traceback
from torch.cuda.amp import autocast, GradScaler

# Th√™m class ExponentialMovingAverage ƒë·ªÉ ·ªïn ƒë·ªãnh qu√° tr√¨nh hu·∫•n luy·ªán
class ExponentialMovingAverage:
    """
    Implement EMA (Exponential Moving Average) ƒë·ªÉ ·ªïn ƒë·ªãnh hu·∫•n luy·ªán.
    """
    def __init__(self, model, decay=0.999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        
        # Kh·ªüi t·∫°o shadow parameters
        for name, param in model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()
    
    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data
                self.shadow[name] = new_average.clone()
    
    def apply_shadow(self):
        # Backup current parameters for restore later
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.backup[name] = param.data.clone()
                param.data = self.shadow[name]
    
    def restore(self):
        # Restore backed up parameters
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                param.data = self.backup[name]

# Th√™m class EarlyStopping ƒë·ªÉ d·ª´ng hu·∫•n luy·ªán khi kh√¥ng c·∫£i thi·ªán
class EarlyStopping:
    """
    Early stopping ƒë·ªÉ tr√°nh overfitting
    """
    def __init__(self, patience=7, delta=0, path='checkpoint.pt', verbose=True):
        self.patience = patience
        self.delta = delta
        self.path = path
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = float('inf')
    
    def __call__(self, val_loss, model):
        score = -val_loss
        
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f'B·ªô ƒë·∫øm Early Stopping: {self.counter} tr√™n {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0
    
    def save_checkpoint(self, val_loss, model):
        if self.verbose:
            print(f'Validation loss gi·∫£m ({self.val_loss_min:.6f} --> {val_loss:.6f}). ƒêang l∆∞u m√¥ h√¨nh...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

# K·ªπ thu·∫≠t MixUp Loss
class MixUpLoss(nn.Module):
    def __init__(self, criterion):
        super().__init__()
        self.criterion = criterion
        
    def forward(self, pred, y_a, y_b, lam):
        loss_a = self.criterion(pred, y_a)
        loss_b = self.criterion(pred, y_b)
        return lam * loss_a + (1 - lam) * loss_b

# Th√™m ƒë∆∞·ªùng d·∫´n g·ªëc v√†o sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Import c√°c module
from models.convnext_transformer_lite import ConvNeXtTransformerLite
from dataset.lazy_apnea_dataset import LazyApneaSingleDataset as LazyApneaDataset
from dataset.lazy_apnea_dataset import MixUpDataset
try:
    from utils.data_splitting import dependent_subject_split
    from utils.visualization import plot_training_history, plot_confusion_matrix, plot_ahi_comparison
except ImportError:
    print("‚ö†Ô∏è C√°c module trong utils kh√¥ng t√¨m th·∫•y, ƒëang ƒë·ªãnh nghƒ©a l·∫°i c√°c h√†m c·∫ßn thi·∫øt...")
    
    # ƒê·ªãnh nghƒ©a l·∫°i h√†m dependent_subject_split
    from torch.utils.data import Subset, ConcatDataset
    import random
    
    def dependent_subject_split(datasets, patient_ids, train_ratio=0.8, seed=42):
        """
        Chia d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p dependent subject: 
        D·ªØ li·ªáu c·ªßa m·ªói b·ªánh nh√¢n ƒë∆∞·ª£c chia th√†nh t·∫≠p train v√† val
        """
        random.seed(seed)
        train_subsets = []
        val_subsets = []
        
        for ds, patient_id in zip(datasets, patient_ids):
            indices = list(range(len(ds)))
            random.shuffle(indices)
            
            split_idx = int(train_ratio * len(indices))
            train_indices = indices[:split_idx]
            val_indices = indices[split_idx:]
            
            train_subsets.append(Subset(ds, train_indices))
            val_subsets.append(Subset(ds, val_indices))
        
        return train_subsets, val_subsets
    
    # ƒê·ªãnh nghƒ©a c√°c h√†m plot
    def plot_training_history(train_losses, val_losses, train_metrics, val_metrics, 
                            metric_name='F1', save_path=None):
        plt.figure(figsize=(12, 5))
        
        plt.subplot(1, 2, 1)
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Validation Loss')
        plt.title('Loss theo epochs')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.subplot(1, 2, 2)
        plt.plot(train_metrics, label=f'Train {metric_name}')
        plt.plot(val_metrics, label=f'Validation {metric_name}')
        plt.title(f'{metric_name} theo epochs')
        plt.xlabel('Epochs')
        plt.ylabel(metric_name)
        plt.legend()
        
        plt.tight_layout()
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path)
            print(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·∫°i: {save_path}")
        else:
            plt.show()
        plt.close()

    def plot_confusion_matrix(y_true, y_pred, classes, save_path=None):
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
        plt.title('Ma tr·∫≠n nh·∫ßm l·∫´n')
        plt.ylabel('Nh√£n th·ª±c t·∫ø')
        plt.xlabel('Nh√£n d·ª± ƒëo√°n')
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path)
            print(f"üìä ƒê√£ l∆∞u ma tr·∫≠n nh·∫ßm l·∫´n t·∫°i: {save_path}")
        else:
            plt.show()
        plt.close()
    
    def plot_ahi_comparison(true_ahi, pred_ahi, patient_ids=None, save_path=None):
        plt.figure(figsize=(12, 6))
        plt.scatter(true_ahi, pred_ahi, alpha=0.7)
        max_val = max(max(true_ahi), max(pred_ahi))
        plt.plot([0, max_val], [0, max_val], 'k--')
        plt.xlabel('AHI th·ª±c t·∫ø')
        plt.ylabel('AHI d·ª± ƒëo√°n')
        plt.title('So s√°nh AHI th·ª±c t·∫ø v√† d·ª± ƒëo√°n')
        
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path)
            print(f"üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì AHI t·∫°i: {save_path}")
        else:
            plt.show()
        plt.close()

# ƒê·ªãnh nghƒ©a c√°c h√†m li√™n quan ƒë·∫øn AHI
def calculate_ahi_from_predictions(y_true, y_pred, block_duration_sec=30):
    """
    T√≠nh AHI t·ª´ nh√£n th·ª±c t·∫ø v√† nh√£n d·ª± ƒëo√°n.
    """
    # ƒê·∫£m b·∫£o y_pred l√† 0 ho·∫∑c 1
    if y_pred.dtype != int:
        y_pred = (y_pred > 0.5).astype(int)

    # T√≠nh s·ªë gi·ªù
    total_hours = (len(y_true) * block_duration_sec) / 3600
    
    # T√≠nh AHI
    true_apnea_count = np.sum(y_true)
    pred_apnea_count = np.sum(y_pred)
    
    true_ahi = true_apnea_count / total_hours if total_hours > 0 else 0
    pred_ahi = pred_apnea_count / total_hours if total_hours > 0 else 0
    
    # C√°c ch·ªâ s·ªë ƒë√°nh gi√°
    mae = abs(true_ahi - pred_ahi)
    rmse = np.sqrt((true_ahi - pred_ahi)**2)
    
    metrics = {
        "mae": mae,
        "rmse": rmse
    }
    
    return true_ahi, pred_ahi, metrics

def classify_osa_severity(ahi):
    """
    Ph√¢n lo·∫°i m·ª©c ƒë·ªô nghi√™m tr·ªçng c·ªßa OSA d·ª±a tr√™n AHI
    """
    if ahi < 5:
        return "B√¨nh th∆∞·ªùng"
    elif ahi < 15:
        return "Nh·∫π"
    elif ahi < 30:
        return "Trung b√¨nh"
    else:
        return "N·∫∑ng"

def set_seed(seed=42):
    """
    ƒê·∫∑t seed cho t√°i t·∫°o k·∫øt qu·∫£
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def train_model(model, train_loader, val_loader, epochs=20, lr=3e-4, device='cuda', 
                patience=7, use_amp=True, use_mixup=False, mixup_alpha=0.2, 
                use_swa=True, swa_start=5, swa_freq=1):
    """
    Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh v·ªõi nhi·ªÅu k·ªπ thu·∫≠t ti√™n ti·∫øn
    
    Tham s·ªë:
        model: M√¥ h√¨nh c·∫ßn hu·∫•n luy·ªán
        train_loader: DataLoader cho t·∫≠p hu·∫•n luy·ªán
        val_loader: DataLoader cho t·∫≠p validation
        epochs: S·ªë epoch hu·∫•n luy·ªán
        lr: T·ªëc ƒë·ªô h·ªçc
        device: Thi·∫øt b·ªã hu·∫•n luy·ªán (cuda/cpu)
        patience: S·ªë epoch ch·ªù tr∆∞·ªõc khi d·ª´ng s·ªõm
        use_amp: S·ª≠ d·ª•ng Automatic Mixed Precision
        use_mixup: S·ª≠ d·ª•ng k·ªπ thu·∫≠t MixUp
        mixup_alpha: H·ªá s·ªë alpha cho MixUp
        use_swa: S·ª≠ d·ª•ng Stochastic Weight Averaging
        swa_start: Epoch b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng SWA
        swa_freq: T·∫ßn su·∫•t c·∫≠p nh·∫≠t SWA
        
    Tr·∫£ v·ªÅ:
        model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
        best_val_f1: Gi√° tr·ªã F1 t·ªët nh·∫•t ƒë·∫°t ƒë∆∞·ª£c
    """
    print(f"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh {model.__class__.__name__} tr√™n {device}")
    
    # Kh·ªüi t·∫°o EMA (Exponential Moving Average)
    ema = ExponentialMovingAverage(model, decay=0.999)
    
    # Early stopping
    checkpoint_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'checkpoints', f'{model.__class__.__name__}_best.pth')
    early_stopping = EarlyStopping(patience=patience, path=checkpoint_path, verbose=True)
    
    # T√≠nh class weights ƒë·ªÉ x·ª≠ l√Ω imbalance
    all_labels = []
    for _, y in train_loader:
        if isinstance(y, tuple):  # MixUp returns (y_a, y_b, lam)
            all_labels.extend(y[0].numpy())
        else:
            all_labels.extend(y.numpy())
    
    unique_labels, label_counts = np.unique(all_labels, return_counts=True)
    class_weights = torch.tensor(
        1.0 / label_counts, 
        dtype=torch.float32, 
        device=device
    )
    class_weights = class_weights / class_weights.sum() * len(class_weights)
    print(f"Tr·ªçng s·ªë l·ªõp: {class_weights.cpu().numpy()}")
    
    # Kh·ªüi t·∫°o loss function v·ªõi tr·ªçng s·ªë m·∫°nh h∆°n cho l·ªõp thi·ªÉu s·ªë
    # TƒÉng g·∫•p ƒë√¥i tr·ªçng s·ªë cho l·ªõp Ng∆∞ng th·ªü (class 1)
    enhanced_weights = class_weights.clone()
    if len(enhanced_weights) > 1:
        enhanced_weights[1] = enhanced_weights[1] * 2.0
        # Chu·∫©n h√≥a l·∫°i
        enhanced_weights = enhanced_weights / enhanced_weights.sum() * len(enhanced_weights)
        print(f"Tr·ªçng s·ªë l·ªõp m·∫°nh h∆°n: {enhanced_weights.cpu().numpy()}")
    
    criterion = nn.CrossEntropyLoss(weight=enhanced_weights)
    
    # Kh·ªüi t·∫°o MixUpLoss n·∫øu s·ª≠ d·ª•ng mixup
    if use_mixup:
        mixup_criterion = MixUpLoss(criterion)
    
    # Kh·ªüi t·∫°o optimizer v·ªõi weight decay v√† AdamW
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    
    # Th√™m focal loss para ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ m·∫•t c√¢n b·∫±ng
    focal_gamma = 2.0  # Tham s·ªë gamma cho focal loss (tƒÉng tr·ªçng s·ªë cho c√°c m·∫´u kh√≥ ph√¢n lo·∫°i)
    print(f"S·ª≠ d·ª•ng Focal Loss v·ªõi gamma={focal_gamma}")
    
    # S·ª≠ d·ª•ng OneCycleLR v·ªõi warm-up v√† cosine annealing
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer, 
        max_lr=lr,
        epochs=epochs,
        steps_per_epoch=len(train_loader),
        pct_start=0.1,  # 10% c·ªßa epochs cho warm-up
        div_factor=25,  # lr_start = max_lr/25
        final_div_factor=1000,  # lr_end = lr_start/1000
        anneal_strategy='cos'
    )
    
    # Kh·ªüi t·∫°o GradScaler cho Automatic Mixed Precision (AMP)
    scaler = GradScaler() if use_amp else None
    
    # Kh·ªüi t·∫°o Stochastic Weight Averaging n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if use_swa:
        swa_model = torch.optim.swa_utils.AveragedModel(model)
        swa_scheduler = torch.optim.swa_utils.SWALR(
            optimizer, anneal_strategy="linear", 
            anneal_epochs=5, swa_lr=lr/10
        )
    
    best_val_f1 = 0
    
    # L∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    train_f1s, val_f1s = [], []
    
    for epoch in range(epochs):
        # TRAIN
        model.train()
        train_loss = 0
        all_preds, all_labels = [], []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]")
        for batch_idx, batch_data in enumerate(pbar):
            try:
                # X·ª≠ l√Ω d·ªØ li·ªáu MixUp
                if use_mixup and len(batch_data) == 4:
                    x, y_a, y_b, lam = batch_data
                    x = x.to(device)
                    y_a, y_b = y_a.to(device), y_b.to(device)
                    
                    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
                    if x.size(0) == 0 or y_a.size(0) == 0 or y_b.size(0) == 0:
                        print(f"‚ö†Ô∏è B·ªè qua batch {batch_idx} do r·ªóng")
                        continue
                else:
                    x, y = batch_data
                    
                    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
                    if x.size(0) == 0 or y.size(0) == 0:
                        print(f"‚ö†Ô∏è B·ªè qua batch {batch_idx} do r·ªóng")
                        continue
                    
                    x, y = x.to(device), y.to(device)
                
                optimizer.zero_grad()
                
                # S·ª≠ d·ª•ng AMP n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
                if use_amp:
                    with autocast():
                        pred = model(x)
                        
                        if use_mixup and len(batch_data) == 4:
                            loss = mixup_criterion(pred, y_a, y_b, lam)
                        else:
                            # Th√™m focal loss component
                            probs = torch.softmax(pred, dim=1)
                            pt = probs.gather(1, y.view(-1, 1)).squeeze(1)
                            focal_weight = (1 - pt).pow(focal_gamma)
                            loss = criterion(pred, y)
                            loss = (focal_weight * loss).mean()
                    
                    # Scale gradients v√† t·ªëi ∆∞u h√≥a
                    scaler.scale(loss).backward()
                    scaler.unscale_(optimizer)
                    
                    # Th√™m gradient clipping ƒë·ªÉ ·ªïn ƒë·ªãnh hu·∫•n luy·ªán
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    pred = model(x)
                    
                    if use_mixup and len(batch_data) == 4:
                        loss = mixup_criterion(pred, y_a, y_b, lam)
                    else:
                        # Th√™m focal loss component
                        probs = torch.softmax(pred, dim=1)
                        pt = probs.gather(1, y.view(-1, 1)).squeeze(1)
                        focal_weight = (1 - pt).pow(focal_gamma)
                        loss = criterion(pred, y)
                        loss = (focal_weight * loss).mean()
                    
                    loss.backward()
                    
                    # Th√™m gradient clipping ƒë·ªÉ ·ªïn ƒë·ªãnh hu·∫•n luy·ªán
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                
                # C·∫≠p nh·∫≠t EMA sau m·ªói b∆∞·ªõc optimizer
                ema.update()
                
                # C·∫≠p nh·∫≠t learning rate v·ªõi OneCycleLR
                scheduler.step()
                
                train_loss += loss.item()
                
                # L∆∞u d·ª± ƒëo√°n v√† nh√£n cho t√≠nh to√°n metrics
                if use_mixup and len(batch_data) == 4:
                    # V·ªõi MixUp, ch√∫ng ta s·ª≠ d·ª•ng nh√£n g·ªëc (y_a) cho ƒë√°nh gi√°
                    preds = pred.argmax(1).detach().cpu().numpy()
                    all_preds.extend(preds)
                    all_labels.extend(y_a.cpu().numpy())
                else:
                    preds = pred.argmax(1).detach().cpu().numpy()
                    all_preds.extend(preds)
                    all_labels.extend(y.cpu().numpy())
                
                # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
                curr_lr = optimizer.param_groups[0]['lr']
                pbar.set_postfix({
                    'loss': f"{loss.item():.4f}", 
                    'avg_loss': f"{train_loss/(batch_idx+1):.4f}",
                    'lr': f"{curr_lr:.6f}"
                })
                    
            except Exception as e:
                print(f"‚ùå L·ªói ·ªü batch {batch_idx}: {e}")
                continue
        
        if len(all_preds) == 0:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá trong epoch n√†y!")
            continue
        
        train_loss /= len(train_loader)
        train_acc = accuracy_score(all_labels, all_preds)
        train_f1 = f1_score(all_labels, all_preds, average='weighted')
        
        # C·∫≠p nh·∫≠t SWA sau khi ƒë·∫°t ƒë·∫øn swa_start
        if use_swa and epoch >= swa_start and (epoch - swa_start) % swa_freq == 0:
            swa_model.update_parameters(model)
            swa_scheduler.step()
        
        # VALIDATE v·ªõi EMA
        # √Åp d·ª•ng EMA cho ƒë√°nh gi√°
        ema.apply_shadow()
        
        model.eval()
        val_loss = 0
        all_preds, all_labels = [], []
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]")
            for batch_idx, (x, y) in enumerate(pbar):
                try:
                    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
                    if x.size(0) == 0 or y.size(0) == 0:
                        print(f"‚ö†Ô∏è B·ªè qua batch validation {batch_idx} do r·ªóng")
                        continue
                    
                    x, y = x.to(device), y.to(device)
                    
                    if use_amp:
                        with autocast():
                            pred = model(x)
                            loss = criterion(pred, y)
                    else:
                        pred = model(x)
                        loss = criterion(pred, y)
                    
                    val_loss += loss.item()
                    preds = pred.argmax(1).detach().cpu().numpy()
                    all_preds.extend(preds)
                    all_labels.extend(y.cpu().numpy())
                    
                    # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
                    pbar.set_postfix({
                        'loss': f"{loss.item():.4f}", 
                        'avg_loss': f"{val_loss/(batch_idx+1):.4f}"
                    })
                    
                except Exception as e:
                    print(f"‚ùå L·ªói ·ªü batch validation {batch_idx}: {e}")
                    continue
        
        # Restore l·∫°i model weights g·ªëc
        ema.restore()
        
        if len(all_preds) == 0:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu validation h·ª£p l·ªá trong epoch n√†y!")
            continue
        
        val_loss /= len(val_loader)
        val_acc = accuracy_score(all_labels, all_preds)
        
        # Ki·ªÉm tra ph√¢n b·ªë nh√£n v√† d·ª± ƒëo√°n
        unique_labels, label_counts = np.unique(all_labels, return_counts=True)
        unique_preds, pred_counts = np.unique(all_preds, return_counts=True)
        
        print(f"\nPh√¢n b·ªë nh√£n th·ª±c t·∫ø: {dict(zip(unique_labels, label_counts))}")
        print(f"Ph√¢n b·ªë nh√£n d·ª± ƒëo√°n: {dict(zip(unique_preds, pred_counts))}")
        
        # T√≠nh F1 score v·ªõi c·∫£nh b√°o zero_division
        if len(np.unique(all_preds)) == 1:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: M√¥ h√¨nh ch·ªâ d·ª± ƒëo√°n m·ªôt l·ªõp ({np.unique(all_preds)[0]}) trong validation")
            val_f1 = 0.0 if np.unique(all_preds)[0] != np.unique(all_labels)[0] else 1.0
        else:
            val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
        
        # L∆∞u m√¥ h√¨nh t·ªët nh·∫•t d·ª±a tr√™n F1 score
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            os.makedirs(os.path.join(os.path.dirname(os.path.dirname(__file__)), 'checkpoints'), exist_ok=True)
            best_model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'checkpoints', f'{model.__class__.__name__}_best_f1.pth')
            torch.save(model.state_dict(), best_model_path)
            
            # Chi ti·∫øt k·∫øt qu·∫£
            precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
            recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
            cm = confusion_matrix(all_labels, all_preds)
            print(f"Ma tr·∫≠n nh·∫ßm l·∫´n:\n{cm}")
            print(f"ƒê·ªô ch√≠nh x√°c: {precision:.4f}, ƒê·ªô ph·ªß: {recall:.4f}")
        
        # Ki·ªÉm tra early stopping
        early_stopping(val_loss, model)
        if early_stopping.early_stop:
            print(f"Early stopping ƒë∆∞·ª£c k√≠ch ho·∫°t sau epoch {epoch+1}")
            break
        
        # L∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)
        train_f1s.append(train_f1)
        val_f1s.append(val_f1)
        
        print(f"[Epoch {epoch+1}/{epochs}] "
              f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | "
              f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}")
    
    # Finalize SWA sau khi hu·∫•n luy·ªán k·∫øt th√∫c
    if use_swa and epoch >= swa_start:
        print("ƒêang ho√†n thi·ªán m√¥ h√¨nh SWA...")
        # C·∫≠p nh·∫≠t BatchNorm statistics cho SWA model
        torch.optim.swa_utils.update_bn(train_loader, swa_model)
        
        # L∆∞u SWA model
        swa_model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'checkpoints', f'{model.__class__.__name__}_swa.pth')
        torch.save(swa_model.state_dict(), swa_model_path)
        
        # ƒê√°nh gi√° SWA model tr√™n t·∫≠p validation
        swa_model.eval()
        all_preds, all_labels = [], []
        
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(device), y.to(device)
                pred = swa_model(x)
                preds = pred.argmax(1).detach().cpu().numpy()
                all_preds.extend(preds)
                all_labels.extend(y.cpu().numpy())
        
        swa_val_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
        swa_val_acc = accuracy_score(all_labels, all_preds)
        
        print(f"ƒê√°nh gi√° m√¥ h√¨nh SWA - Acc: {swa_val_acc:.4f}, F1: {swa_val_f1:.4f}")
        
        if swa_val_f1 > best_val_f1:
            print(f"M√¥ h√¨nh SWA t·ªët h∆°n m√¥ h√¨nh t·ªët nh·∫•t (F1: {swa_val_f1:.4f} > {best_val_f1:.4f})")
            model.load_state_dict(swa_model.state_dict())
    
    # V·∫Ω bi·ªÉu ƒë·ªì l·ªãch s·ª≠ hu·∫•n luy·ªán
    results_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'results')
    os.makedirs(results_dir, exist_ok=True)
    
    plot_training_history(
        train_losses, val_losses, 
        train_f1s, val_f1s,
        metric_name='F1', 
        save_path=os.path.join(results_dir, f"{model.__class__.__name__}_training_history.png")
    )
    
    # L∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán
    np.savez(
        os.path.join(results_dir, f"{model.__class__.__name__}_history.npz"),
        train_losses=np.array(train_losses),
        val_losses=np.array(val_losses),
        train_accs=np.array(train_accs),
        val_accs=np.array(val_accs),
        train_f1s=np.array(train_f1s),
        val_f1s=np.array(val_f1s),
    )
    
    return model, best_val_f1

def evaluate_ahi(model, patient_datasets, device='cuda'):
    """
    ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·ª´ng b·ªánh nh√¢n v√† t√≠nh AHI
    """
    true_ahis = []
    pred_ahis = []
    patient_ids = []
    ahi_results = {}
    
    results_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'results')
    os.makedirs(results_dir, exist_ok=True)
    
    for patient_id, dataset in patient_datasets.items():
        print(f"‚è≥ ƒê√°nh gi√° b·ªánh nh√¢n {patient_id}...")
        
        # DataLoader cho b·ªánh nh√¢n
        patient_loader = DataLoader(dataset, batch_size=32, shuffle=False)
        
        # D·ª± ƒëo√°n
        model.eval()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for x, y in tqdm(patient_loader, desc=f"D·ª± ƒëo√°n cho b·ªánh nh√¢n {patient_id}"):
                try:
                    x = x.to(device)
                    outputs = model(x)
                    preds = outputs.argmax(1).cpu().numpy()
                    all_preds.extend(preds)
                    all_labels.extend(y.numpy())
                except Exception as e:
                    print(f"‚ùå L·ªói khi d·ª± ƒëo√°n: {e}")
                    continue
        
        # T√≠nh AHI
        if len(all_preds) > 0:
            true_ahi, pred_ahi, metrics = calculate_ahi_from_predictions(
                np.array(all_labels), np.array(all_preds)
            )
            
            true_severity = classify_osa_severity(true_ahi)
            pred_severity = classify_osa_severity(pred_ahi)
            
            print(f"  AHI th·ª±c t·∫ø: {true_ahi:.2f} ({true_severity})")
            print(f"  AHI d·ª± ƒëo√°n: {pred_ahi:.2f} ({pred_severity})")
            print(f"  MAE: {metrics['mae']:.2f}, RMSE: {metrics['rmse']:.2f}")
            
            true_ahis.append(true_ahi)
            pred_ahis.append(pred_ahi)
            patient_ids.append(patient_id)
            
            ahi_results[patient_id] = {
                'true_ahi': true_ahi,
                'pred_ahi': pred_ahi,
                'true_severity': true_severity,
                'pred_severity': pred_severity,
                'metrics': metrics
            }
    
    # L∆∞u k·∫øt qu·∫£
    np.savez(
        os.path.join(results_dir, 'ahi_evaluation.npz'),
        patient_ids=np.array(patient_ids),
        true_ahis=np.array(true_ahis),
        pred_ahis=np.array(pred_ahis)
    )
    
    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh AHI
    if len(true_ahis) > 0:
        plot_ahi_comparison(
            true_ahis, 
            pred_ahis,
            patient_ids=patient_ids,
            save_path=os.path.join(results_dir, 'ahi_comparison.png')
        )
        
        # T·∫°o confusion matrix cho ph√¢n lo·∫°i OSA
        true_severities = [classify_osa_severity(ahi) for ahi in true_ahis]
        pred_severities = [classify_osa_severity(ahi) for ahi in pred_ahis]
        
        severity_classes = ['B√¨nh th∆∞·ªùng', 'Nh·∫π', 'Trung b√¨nh', 'N·∫∑ng']
        severity_mapping = {'B√¨nh th∆∞·ªùng': 0, 'Nh·∫π': 1, 'Trung b√¨nh': 2, 'N·∫∑ng': 3}
        
        true_classes = [severity_mapping[s] for s in true_severities]
        pred_classes = [severity_mapping[s] for s in pred_severities]
        
        cm = confusion_matrix(true_classes, pred_classes, labels=range(len(severity_classes)))
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=severity_classes, yticklabels=severity_classes)
        plt.title('Ph√¢n lo·∫°i m·ª©c ƒë·ªô nghi√™m tr·ªçng OSA')
        plt.ylabel('M·ª©c ƒë·ªô th·ª±c t·∫ø')
        plt.xlabel('M·ª©c ƒë·ªô d·ª± ƒëo√°n')
        plt.savefig(os.path.join(results_dir, 'osa_severity_confusion.png'))
        plt.close()
    
    return true_ahis, pred_ahis, patient_ids, ahi_results

def main():
    """
    H√†m ch√≠nh th·ª±c hi·ªán qu√° tr√¨nh hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh
    """
    # X·ª≠ l√Ω tham s·ªë d√≤ng l·ªánh t·ª´ bi·∫øn args to√†n c·ª•c
    # ƒê√£ ƒë∆∞·ª£c x·ª≠ l√Ω ·ªü ph·∫ßn if __name__ == "__main__"
    
    # ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu
    project_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    
    # N·∫øu data_dir ƒë∆∞·ª£c cung c·∫•p, d√πng n√≥ ƒë·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n
    if args.data_dir:
        # X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ho·∫∑c tuy·ªát ƒë·ªëi
        if os.path.isabs(args.data_dir):
            data_dir = args.data_dir
        else:
            # X·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi t·ª´ v·ªã tr√≠ hi·ªán t·∫°i
            data_dir = os.path.abspath(os.path.join(os.getcwd(), args.data_dir))
            
            # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, th·ª≠ t·ª´ th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
            if not os.path.exists(data_dir):
                data_dir = os.path.abspath(os.path.join(project_dir, args.data_dir))
    else:
        # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh
        data_dir = os.path.join(project_dir, "data", "blocks")
    
    print(f"üîç ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu: {data_dir}")
    
    # Ki·ªÉm tra t·ªìn t·∫°i c·ªßa th∆∞ m·ª•c d·ªØ li·ªáu
    if not os.path.exists(data_dir):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c blocks t·∫°i {data_dir}")
        print(f"‚ö†Ô∏è Th∆∞ m·ª•c hi·ªán t·∫°i: {os.getcwd()}")
        print("‚ö†Ô∏è Vui l√≤ng ch·∫°y build_dataset.py tr∆∞·ªõc ho·∫∑c ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n")
        return
    
    # T·ªïng h·ª£p d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ c√°c b·ªánh nh√¢n
    try:
        patient_dirs = [os.path.join(data_dir, d) for d in os.listdir(data_dir) 
                      if os.path.isdir(os.path.join(data_dir, d))]
        
        print(f"üìä ƒêang t·∫£i d·ªØ li·ªáu t·ª´ {len(patient_dirs)} b·ªánh nh√¢n")
        
        datasets = []
        patient_ids = []
        patient_datasets = {}
        
        for p_dir in patient_dirs:
            try:
                patient_id = os.path.basename(p_dir)
                ds = LazyApneaDataset(p_dir)
                if len(ds) > 0:
                    datasets.append(ds)
                    patient_ids.append(patient_id)
                    patient_datasets[patient_id] = ds
                    print(f"‚úÖ ƒê√£ t·∫£i {len(ds)} m·∫´u t·ª´ {patient_id}")
            except Exception as e:
                print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ {p_dir}: {e}")
        
        if not datasets:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán. Vui l√≤ng ch·∫°y build_dataset.py tr∆∞·ªõc.")
            return
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return
    
    # Chia d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p dependent subject
    print("\nüîÄ ƒêang chia d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p dependent subject...")
    try:
        train_datasets, val_datasets = dependent_subject_split(
            datasets, patient_ids, train_ratio=0.8, seed=42
        )
        
        # T·∫°o combined datasets
        train_dataset = ConcatDataset(train_datasets)
        val_dataset = ConcatDataset(val_datasets)
        
        print(f"üìà T·ªïng s·ªë m·∫´u: {len(train_dataset)} train, {len(val_dataset)} validation")
        
        # Ki·ªÉm tra t√≠nh hi·ªáu qu·∫£ c·ªßa ph∆∞∆°ng ph√°p dependent subject
        print("\nüîç Ki·ªÉm tra ph∆∞∆°ng ph√°p dependent subject:")
        for i, (p_id, p_ds) in enumerate(zip(patient_ids, datasets)):
            train_count = len(train_datasets[i])
            val_count = len(val_datasets[i])
            total = len(p_ds)
            print(f"  {p_id}: {train_count}/{total} ({train_count/total*100:.1f}%) train, "
                  f"{val_count}/{total} ({val_count/total*100:.1f}%) validation")
    except Exception as e:
        print(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {e}")
        return
    
    # Ki·ªÉm tra ph√¢n b·ªë nh√£n trong t·∫≠p train
    print("\nüìä Ki·ªÉm tra ph√¢n b·ªë nh√£n:")
    train_labels = []
    val_labels = []
    
    # L·∫•y t·∫•t c·∫£ c√°c nh√£n t·ª´ t·∫≠p train
    for ds in train_datasets:
        for i in range(len(ds)):
            _, label = ds[i]
            train_labels.append(label)
    
    # L·∫•y t·∫•t c·∫£ c√°c nh√£n t·ª´ t·∫≠p validation
    for ds in val_datasets:
        for i in range(len(ds)):
            _, label = ds[i]
            val_labels.append(label)
    
    # T√≠nh to√°n class weights cho loss
    train_labels_np = np.array(train_labels)
    num_samples = len(train_labels_np)
    num_classes = 2  # B√¨nh th∆∞·ªùng v√† Ng∆∞ng th·ªü
    
    class_counts = [np.sum(train_labels_np == i) for i in range(num_classes)]
    print(f"  T·∫≠p train: B√¨nh th∆∞·ªùng: {class_counts[0]}, Ng∆∞ng th·ªü: {class_counts[1]}")
    
    # T√≠nh tr·ªçng s·ªë c√°c l·ªõp cho t·∫≠p train - ∆∞u ti√™n m·∫°nh h∆°n cho l·ªõp thi·ªÉu s·ªë
    # S·ª≠ d·ª•ng c√¥ng th·ª©c c√¢n b·∫±ng m·∫°nh h∆°n
    total = sum(class_counts)
    class_weights = [total / (num_classes * count) for count in class_counts]
    print(f"  Tr·ªçng s·ªë: B√¨nh th∆∞·ªùng: {class_weights[0]:.2f}, Ng∆∞ng th·ªü: {class_weights[1]:.2f}")
    
    # T√≠nh ph√¢n b·ªë nh√£n cho t·∫≠p validation
    val_labels_np = np.array(val_labels)
    val_class_counts = [np.sum(val_labels_np == i) for i in range(num_classes)]
    print(f"  T·∫≠p validation: B√¨nh th∆∞·ªùng: {val_class_counts[0]}, Ng∆∞ng th·ªü: {val_class_counts[1]}")
    
    # Ki·ªÉm tra ph√¢n b·ªë l·ªõp trong t·∫≠p hu·∫•n luy·ªán v√† validation
    print("\nüìä Ki·ªÉm tra ph√¢n b·ªë l·ªõp (class distribution):")
    
    # T·∫≠p hu·∫•n luy·ªán
    train_labels = []
    for ds in train_datasets:
        for _, y in ds:
            train_labels.append(y.item())
    
    train_unique, train_counts = np.unique(train_labels, return_counts=True)
    print(f"  Train: {dict(zip(train_unique, train_counts))}")
    
    # T·∫≠p validation
    val_labels = []
    for ds in val_datasets:
        for _, y in ds:
            val_labels.append(y.item())
    
    val_unique, val_counts = np.unique(val_labels, return_counts=True)
    print(f"  Validation: {dict(zip(val_unique, val_counts))}")
    
    # T√≠nh t·ª∑ l·ªá m·∫•t c√¢n b·∫±ng v√† hi·ªÉn th·ªã
    if len(train_unique) > 1:
        imbalance_ratio = max(train_counts) / min(train_counts)
        print(f"  T·ª∑ l·ªá m·∫•t c√¢n b·∫±ng: {imbalance_ratio:.2f}")
        
        # T√≠nh tr·ªçng s·ªë ngh·ªãch ƒë·∫£o cho t·ª´ng l·ªõp
        class_weights = len(train_labels) / (len(train_unique) * train_counts)
        print(f"  Tr·ªçng s·ªë l·ªõp: {dict(zip(train_unique, class_weights))}")
    
    # T·∫°o DataLoader v·ªõi c√°c t√πy ch·ªçn ti√™n ti·∫øn
    try:
        # DataLoader cho t·∫≠p hu·∫•n luy·ªán
        if args.balance_classes:
            print("\n‚öñÔ∏è ƒêang c√¢n b·∫±ng d·ªØ li·ªáu cho t·∫≠p train...")
            samples_weight = np.array([class_weights[t] for t in train_labels])
            samples_weight = torch.from_numpy(samples_weight).float()
            sampler = WeightedRandomSampler(samples_weight, len(samples_weight))
            train_loader = DataLoader(
                train_dataset, 
                batch_size=args.batch_size,
                sampler=sampler,
                num_workers=args.num_workers,
                pin_memory=True
            )
        else:
            # S·ª≠ d·ª•ng MixUp dataset n·∫øu c·∫ßn
            if args.use_mixup:
                print("\nüîÑ ƒêang √°p d·ª•ng k·ªπ thu·∫≠t MixUp...")
                try:
                    mixup_dataset = MixUpDataset(train_dataset, alpha=args.mixup_alpha)
                    train_loader = DataLoader(
                        mixup_dataset, 
                        batch_size=args.batch_size,
                        shuffle=True,
                        num_workers=args.num_workers,
                        pin_memory=True
                    )
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi t·∫°o MixUp dataset: {e}. S·ª≠ d·ª•ng dataset th√¥ng th∆∞·ªùng.")
                    train_loader = DataLoader(
                        train_dataset, 
                        batch_size=args.batch_size,
                        shuffle=True,
                        num_workers=args.num_workers,
                        pin_memory=True
                    )
            else:
                train_loader = DataLoader(
                    train_dataset, 
                    batch_size=args.batch_size,
                    shuffle=True,
                    num_workers=args.num_workers,
                    pin_memory=True
                )
        
        # DataLoader cho t·∫≠p validation
        val_loader = DataLoader(
            val_dataset, 
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers,
            pin_memory=True
        )
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o DataLoader: {e}")
        return
    
    # Ch·ªçn thi·∫øt b·ªã
    device = torch.device(args.device if torch.cuda.is_available() and args.device == 'cuda' else 'cpu')
    print(f"\nüñ•Ô∏è S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}")
    
    # T·∫°o class weights tensor cho loss function
    class_weights_tensor = torch.FloatTensor(class_weights).to(device)
    
    # Kh·ªüi t·∫°o m√¥ h√¨nh
    try:
        model = ConvNeXtTransformerLite(num_classes=2).to(device)
        print(f"‚úÖ Kh·ªüi t·∫°o m√¥ h√¨nh {model.__class__.__name__} th√†nh c√¥ng")
    except Exception as e:
        print(f"‚ùå L·ªói khi kh·ªüi t·∫°o m√¥ h√¨nh: {e}")
        return
    
    # Hu·∫•n luy·ªán ho·∫∑c t·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    try:
        if not args.eval_only:
            # T·∫°o th∆∞ m·ª•c checkpoints n·∫øu ch∆∞a t·ªìn t·∫°i
            checkpoint_dir = os.path.join(project_dir, 'checkpoints')
            os.makedirs(checkpoint_dir, exist_ok=True)
            
            print(f"\nüöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi {args.epochs} epochs...")
            model, best_val_f1 = train_model(
                model, 
                train_loader, 
                val_loader, 
                epochs=args.epochs, 
                lr=args.learning_rate,
                device=device,
                use_amp=args.use_amp,
                use_mixup=args.use_mixup,
                mixup_alpha=args.mixup_alpha,
                use_swa=args.use_swa
            )
            print(f"\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t. F1 t·ªët nh·∫•t: {best_val_f1:.4f}")
        else:
            # T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
            checkpoint_path = os.path.join(project_dir, 'checkpoints', f'{model.__class__.__name__}_best.pth')
            if os.path.exists(checkpoint_path):
                model.load_state_dict(torch.load(checkpoint_path, map_location=device))
                print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {checkpoint_path}")
            else:
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y checkpoint t·∫°i {checkpoint_path}")
                return
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán/t·∫£i m√¥ h√¨nh: {e}")
        return
    
    # ƒê√°nh gi√° tr√™n t·∫≠p validation v√† v·∫Ω confusion matrix
    try:
        print("\nüìä ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p validation...")
        model.eval()
        all_preds, all_labels = [], []
        
        with torch.no_grad():
            for batch_idx, (x, y) in enumerate(tqdm(val_loader, desc="ƒê√°nh gi√° tr√™n t·∫≠p validation")):
                try:
                    if x.size(0) == 0:
                        continue
                    x = x.to(device)
                    outputs = model(x)
                    preds = outputs.argmax(1)
                    
                    all_preds.extend(preds.cpu().numpy())
                    all_labels.extend(y.numpy())
                except Exception as e:
                    print(f"‚ùå L·ªói khi ƒë√°nh gi√° batch {batch_idx}: {e}")            # T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√°
            accuracy = accuracy_score(all_labels, all_preds)
            # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p khi m√¥ h√¨nh ch·ªâ d·ª± ƒëo√°n m·ªôt l·ªõp
            if len(np.unique(all_preds)) == 1:
                print(f"‚ö†Ô∏è C·∫£nh b√°o: M√¥ h√¨nh ch·ªâ d·ª± ƒëo√°n m·ªôt l·ªõp ({np.unique(all_preds)[0]})")
                f1 = 0.0 if np.unique(all_preds)[0] != np.unique(all_labels)[0] else 1.0
                precision = 0.0 if np.unique(all_preds)[0] != np.unique(all_labels)[0] else 1.0
                recall = 0.0 if np.unique(all_preds)[0] != np.unique(all_labels)[0] else 1.0
            else:
                f1 = f1_score(all_labels, all_preds, average='weighted')
                precision = precision_score(all_labels, all_preds, average='weighted')
                recall = recall_score(all_labels, all_preds, average='weighted')
            
            print(f"\nüìà K·∫øt qu·∫£ ƒë√°nh gi√° tr√™n t·∫≠p validation:")
            print(f"  ƒê·ªô ch√≠nh x√°c: {accuracy:.4f}")
            print(f"  F1-score: {f1:.4f}")
            print(f"  Precision: {precision:.4f}")
            print(f"  Recall: {recall:.4f}")
        
        # V·∫Ω confusion matrix
        results_dir = os.path.join(project_dir, 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        plot_confusion_matrix(
            all_labels, 
            all_preds,
            classes=['B√¨nh th∆∞·ªùng', 'Ng∆∞ng th·ªü'], 
            save_path=os.path.join(results_dir, f"{model.__class__.__name__}_confusion_matrix.png")
        )
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë√°nh gi√° m√¥ h√¨nh: {e}")
        return
    
    # T√≠nh AHI v√† ƒë√°nh gi√°
    try:
        print("\nüìä ƒê√°nh gi√° AHI tr√™n t·ª´ng b·ªánh nh√¢n...")
        true_ahis, pred_ahis, patient_ids, ahi_results = evaluate_ahi(
            model, patient_datasets, device=device
        )
        
        if len(true_ahis) > 0:
            # T√≠nh c√°c ch·ªâ s·ªë ƒë√°nh gi√° t·ªïng h·ª£p
            mae = np.mean(np.abs(np.array(true_ahis) - np.array(pred_ahis)))
            rmse = np.sqrt(np.mean((np.array(true_ahis) - np.array(pred_ahis))**2))
            correlation = np.corrcoef(true_ahis, pred_ahis)[0, 1]
            
            print(f"\nüìà K·∫øt qu·∫£ ƒë√°nh gi√° AHI t·ªïng h·ª£p:")
            print(f"  MAE: {mae:.2f}")
            print(f"  RMSE: {rmse:.2f}")
            print(f"  Correlation: {correlation:.2f}")
            
            # ƒê√°nh gi√° ph√¢n lo·∫°i m·ª©c ƒë·ªô nghi√™m tr·ªçng
            true_severities = [classify_osa_severity(ahi) for ahi in true_ahis]
            pred_severities = [classify_osa_severity(ahi) for ahi in pred_ahis]
            
            # T√≠nh accuracy c·ªßa ph√¢n lo·∫°i m·ª©c ƒë·ªô
            severity_accuracy = sum(t == p for t, p in zip(true_severities, pred_severities)) / len(true_severities)
            print(f"  ƒê·ªô ch√≠nh x√°c ph√¢n lo·∫°i m·ª©c ƒë·ªô: {severity_accuracy:.2f}")
            
            # Th·ªëng k√™ ch√™nh l·ªách
            severity_diff = {}
            for ts, ps in zip(true_severities, pred_severities):
                if ts != ps:
                    key = f"{ts} -> {ps}"
                    severity_diff[key] = severity_diff.get(key, 0) + 1
            
            if severity_diff:
                print("\n‚ö†Ô∏è Ch√™nh l·ªách ph√¢n lo·∫°i m·ª©c ƒë·ªô:")
                for diff, count in severity_diff.items():
                    print(f"  {diff}: {count} b·ªánh nh√¢n")
        
        print("\n‚úÖ Ho√†n t·∫•t ƒë√°nh gi√° m√¥ h√¨nh!")
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë√°nh gi√° AHI: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    # Import c√°c module c·∫ßn thi·∫øt ƒë·ªÉ hi·ªÉn th·ªã traceback chi ti·∫øt khi c√≥ l·ªói
    import traceback
    
    try:
        print("\nüöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh ConvNeXtTransformerLite...")
        parser = argparse.ArgumentParser(description='Hu·∫•n luy·ªán m√¥ h√¨nh ConvNeXtTransformerLite cho ph√°t hi·ªán ng∆∞ng th·ªü khi ng·ªß')
        parser.add_argument('--data_dir', type=str, help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c d·ªØ li·ªáu blocks')
        parser.add_argument('--batch_size', type=int, default=32, help='K√≠ch th∆∞·ªõc batch')
        parser.add_argument('--epochs', type=int, default=20, help='S·ªë epochs hu·∫•n luy·ªán')
        parser.add_argument('--learning_rate', type=float, default=1e-3, help='T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu')
        parser.add_argument('--device', type=str, default='cuda', help='Thi·∫øt b·ªã hu·∫•n luy·ªán (cuda/cpu)')
        parser.add_argument('--num_workers', type=int, default=4, help='S·ªë workers cho DataLoader')
        parser.add_argument('--eval_only', action='store_true', help='Ch·ªâ ƒë√°nh gi√° m√¥ h√¨nh, kh√¥ng hu·∫•n luy·ªán')
        parser.add_argument('--use_amp', action='store_true', help='S·ª≠ d·ª•ng Automatic Mixed Precision')
        parser.add_argument('--use_mixup', action='store_true', help='S·ª≠ d·ª•ng k·ªπ thu·∫≠t MixUp')
        parser.add_argument('--mixup_alpha', type=float, default=0.2, help='H·ªá s·ªë alpha cho MixUp')
        parser.add_argument('--balance_classes', action='store_true', help='C√¢n b·∫±ng l·ªõp b·∫±ng WeightedRandomSampler')
        parser.add_argument('--use_swa', action='store_true', help='S·ª≠ d·ª•ng Stochastic Weight Averaging')
        
        args = parser.parse_args()
        
        # ƒê·∫∑t seed cho t√°i t·∫°o k·∫øt qu·∫£
        set_seed(42)
        
        main()
        print("\n‚úÖ Ch∆∞∆°ng tr√¨nh ho√†n t·∫•t!")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        print("\nüîç Chi ti·∫øt l·ªói:")
        traceback.print_exc()
